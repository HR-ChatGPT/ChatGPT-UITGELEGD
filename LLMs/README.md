# Functioneel Overzicht van OPENAI's Grote Taalmodellen (sinds Mei 2024)

<a id="table-of-contents"></a>
## Inhoudsopgave

1.  [Inleiding](#1-inleiding)
2.  [OpenAI LLM's Uitgebracht Sinds Mei 2024](#2-openai-llms-uitgebracht-sinds-mei-2024)
    * [GPT-4o](#gpt-4o)
    * [GPT-4o mini](#gpt-4o-mini)
      * [o1](#o1)
        * [o1-mini](#o1-mini)
        * [o3](#o3)
        * [o4-mini](#o4-mini)
        * [GPT-4.5](#gpt-4-5)
        * [GPT-4.1 Familie](#gpt-4-1-familie)
        * [Gespecialiseerde Modellen en Updates](#gespecialiseerde-modellen-en-updates)
        * [Tabel: OpenAI LLM Gebieden van Uitmuntendheid](#tabel-openai-llm-gebieden-van-uitmuntendheid)
3.  [Vergelijkende Analyse met Alternatieve LLM's](#3-vergelijkende-analyse-met-alternatieve-llms)
    * [Claude 3.7 Sonnet (Anthropic)](#claude-37-sonnet-anthropic)
    * [Grok-3 (xAI)](#grok-3-xai)
    * [Gemini 2.0 (Google DeepMind)](#gemini-20-google-deepmind)
      * [DeepSeek R1 en V3 (DeepSeek AI)](#deepseek-r1-en-v3-deepseek-ai)
      * [Mistral Large 2 (Mistral AI)](#mistral-large-2-mistral-ai)
      * [Llama 3.1 (Meta AI)](#llama-31-meta-ai)
      * [Phi-3 (Microsoft)](#phi-3-microsoft)
      * [Amazon Nova (Amazon)](#amazon-nova-amazon)
4.  [Samenvattende Tabel van OpenAI en Alternatieve LLM Benchmarks](#4-samenvattende-tabel-van-openai-en-alternatieve-llm-benchmarks)
5.  [Conclusie](#5-conclusie)
6.  [Referenties](#6-referenties)

## 1\. Inleiding

[Inhoudsopgave](#table-of-contents)

Het veld van Grote Taalmodellen (LLM's) heeft de afgelopen jaren opmerkelijke vooruitgang geboekt, gekenmerkt door een snelle toename van mogelijkheden en een groeiende invloed in diverse sectoren. Deze geavanceerde modellen zijn essentieel geworden voor vooruitgang in natuurlijke taalverwerking, waardoor aanzienlijke stappen zijn gezet in taken zoals tekstgeneratie, vertaling en informatieopvraging. OpenAI loopt consequent voorop in deze technologische evolutie, vooral bekend om de ontwikkeling van de GPT-serie modellen, die nieuwe normen hebben gesteld voor prestaties en veelzijdigheid. Toch wordt het LLM-landschap steeds competitiever, met grote onderzoeksorganisaties, technologiebedrijven en innovatieve startups die zeer capabele modellen introduceren die de dominantie van OpenAI uitdagen. Deze dynamische omgeving vereist een voortdurende en gedetailleerde analyse om de laatste ontwikkelingen bij te houden en de relatieve sterktes en specialisaties van de verschillende beschikbare LLM's te begrijpen. Dit rapport beoogt zo'n analyse te bieden, met een specifieke focus op de periode sinds mei 2024, een tijdsbestek waarin aanzienlijke vooruitgang en nieuwe modelreleases van OpenAI en zijn concurrenten zijn waargenomen.

Het primaire doel van dit rapport is een uitgebreid overzicht te geven van alle Grote Taalmodellen (LLM's) die door OpenAI zijn uitgebracht vanaf mei 2024. Naast het beschrijven van deze modellen en hun specifieke sterktes, bevat deze analyse een grondige vergelijkende evaluatie van het aanbod van OpenAI ten opzichte van alternatieve LLM's van andere organisaties die in dezelfde periode zijn uitgebracht of aanzienlijk zijn bijgewerkt. Dit rapport hanteert een technische en analytische benadering, waarbij gebruik wordt gemaakt van openbaar beschikbare gegevens, prestatiebenchmarks en gedocumenteerde mogelijkheden om een robuuste beoordeling van het huidige LLM-landschap te bieden. De beoogde doelgroep voor dit rapport bestaat uit personen met een sterke technische achtergrond in kunstmatige intelligentie en machine learning, waaronder onderzoekers, ontwikkelaars en analisten die een gedetailleerd inzicht zoeken in de stand van zaken op het gebied van LLM-technologie.

De methodologie die in dit rapport wordt gehanteerd, omvat een uitgebreide beoordeling en synthese van openbaar toegankelijke onderzoeksdocumentatie. Dit omvat technische documentatie en systeemkaarten die zijn uitgebracht door OpenAI en andere organisaties, aankondigingen en blogposts met details over nieuwe modelkenmerken en mogelijkheden, en gerapporteerde benchmarkresultaten van verschillende industriestandaard evaluaties. De analyse richt zich op het extraheren van cruciale technische specificaties, belangrijke prestatie-indicatoren en de beoogde gebruiksscenario's voor elk geïdentificeerd LLM, en biedt zo een gedetailleerde en op data gebaseerde vergelijking van hun respectievelijke sterktes en beperkingen.

## 2\. OpenAI LLM's Uitgebracht Sinds Mei 2024

[Inhoudsopgave](#table-of-contents)

Een systematische beoordeling van de beschikbare informatie onthult een divers en uitgebreid portfolio van Grote Taalmodellen die door OpenAI zijn uitgebracht vanaf mei 2024. Deze periode werd gekenmerkt door een hoge frequentie van nieuwe modelintroducties en updates, wat de voortdurende inzet van OpenAI weerspiegelt om de grenzen van AI-mogelijkheden te verleggen. De geïdentificeerde modellen omvatten GPT-4o [1](#ref-1), [2](#ref-2), ... (referenties blijven onvertaald). Deze uitgebreide lijst benadrukt de strategie van OpenAI om modellen te ontwikkelen met verschillende mogelijkheden en kostenstructuren om een breed scala aan toepassingen te bedienen. De introductie van de "o"-serie betekent een gerichte inspanning om de redeneervermogens van hun modellen te verbeteren.

### GPT-4o

[Inhoudsopgave](#table-of-contents)

**GPT-4o**, uitgebracht op 13 mei 2024 [18](#ref-18), is een vlaggenschipmodel met native multimodale mogelijkheden, waarmee tekst, audio en afbeeldingen verwerkt en gegenereerd kunnen worden.[12](#ref-12), [22](#ref-22) De architectuur bestaat uit één end-to-end neuraal netwerk, wat zorgt voor snellere responstijden en verbeterde efficiëntie ten opzichte van eerdere modellen.[18](#ref-18) Belangrijke kenmerken zijn realtime audiogesprekken en verbeterd begrip van niet-Engelse talen en visuele input.[12](#ref-12), [18](#ref-18), [23](#ref-23), [24](#ref-24), [25](#ref-25), [26](#ref-26) GPT-4o is bedoeld voor veelzijdige toepassingen die snelle en intelligente reacties vereisen over verschillende modaliteiten.[2](#ref-2)

### GPT-4o mini

[Inhoudsopgave](#table-of-contents)

**GPT-4o mini**, gelanceerd op 18 juli 2024 [1](#ref-1), is een kleinere, snellere en kostenefficiëntere variant van GPT-4o.[9](#ref-9), [14](#ref-14), [37](#ref-37) Het maakt gebruik van een gestroomlijnde versie van de GPT-4-architectuur [40](#ref-40) en blinkt uit in taken die snelheid en efficiëntie vereisen, zoals coderen, debuggen en realtime interacties.[14](#ref-14) Ondanks het compacte formaat levert GPT-4o mini sterke prestaties in multimodale redeneervaardigheden en behaalt het indrukwekkende scores op academische benchmarks.[5](#ref-5), [34](#ref-34), [37](#ref-37)

### o1

[Inhoudsopgave](#table-of-contents)

De **o1**-modelserie, waarvan de volledige versie werd uitgebracht op 17 december 2024 [8](#ref-8), vertegenwoordigt een nieuwe generatie redeneermodellen die ontworpen zijn om meer tijd te besteden aan "nadenken" voordat ze antwoorden.[50](#ref-50), [55](#ref-55) Dit wordt bereikt door grootschalige reinforcement learning gericht op chain-of-thought-verwerking.[50](#ref-50), [51](#ref-51) o1 blinkt uit in complexe redeneertaken en levert sterke prestaties in bètavakken, waaronder wiskunde, programmeren en wetenschap.[50](#ref-50), [53](#ref-53), [55](#ref-55) Het model toont ook opmerkelijke capaciteiten op het gebied van cybersecurity.[51](#ref-51), [54](#ref-54)

### o1-mini

[Inhoudsopgave](#table-of-contents)

**o1-mini**, uitgebracht op 12 september 2024 [8](#ref-8), is een snellere en kostenefficiëntere versie van o1, vooral effectief bij programmeertaken en andere STEM-taken waarbij brede algemene kennis minder essentieel is.[58](#ref-58), [60](#ref-60)

### o3

[Inhoudsopgave](#table-of-contents)

Het **o3**-model, uitgebracht op 16 april 2025 [1](#ref-1), [6](#ref-6), [8](#ref-8), wordt beschreven als het krachtigste redeneermodel van OpenAI tot nu toe, dat uitblinkt in complexe vragen die een veelzijdige analyse vereisen en state-of-the-art prestaties levert in programmeren, wiskunde, wetenschap en visuele taken.[5](#ref-5), [43](#ref-43), [68](#ref-68) Het kan afbeeldingen direct integreren in zijn redeneerlijn en agentisch gebruikmaken van tools zoals websearch en Python.[5](#ref-5), [49](#ref-49), [68](#ref-68)

### o4-mini

[Inhoudsopgave](#table-of-contents)

**o4-mini**, eveneens uitgebracht op 16 april 2025 [1](#ref-1), [6](#ref-6), [8](#ref-8), is een kleiner model geoptimaliseerd voor snelle en kostenefficiënte redenatie, met opmerkelijke prestaties voor zijn formaat, vooral in wiskunde, programmeren en visuele analyse.[5](#ref-5), [48](#ref-48) Het is het best presterende model op de AIME 2024 en 2025 benchmarks.[5](#ref-5)

### GPT-4.5

[Inhoudsopgave](#table-of-contents)

**GPT-4.5**, uitgebracht als research preview op 27 februari 2025 [1](#ref-1), [6](#ref-6), is het grootste en meest kennisrijke chatmodel van OpenAI tot nu toe.[1](#ref-1), [61](#ref-61) Het bouwt voort op GPT-4o door het opschalen van pre-training en het toepassen van nieuwe supervisietechnieken.[72](#ref-72) GPT-4.5 heeft een bredere kennisbasis, een verbeterd vermogen om gebruikersintentie te volgen en een grotere "EQ", waardoor het nuttig is voor taken als schrijven, programmeren en het oplossen van praktische problemen.[71](#ref-71), [73](#ref-73), [75](#ref-75) Het model vertoont ook sterke feitelijke nauwkeurigheid en hallucineert minder dan andere OpenAI-modellen.[71](#ref-71), [73](#ref-73)

### GPT-4.1 Familie

[Inhoudsopgave](#table-of-contents)

De **GPT-4.1**-familie van modellen, waaronder GPT-4.1, GPT-4.1 mini en GPT-4.1 nano, werd gelanceerd op 14 april 2025.[6](#ref-6), [17](#ref-17), [77](#ref-77) Deze modellen presteren beter dan GPT-4o en GPT-4o mini, met aanzienlijke verbeteringen in programmeren en instructievolging.[17](#ref-17) Ze ondersteunen grotere contextvensters tot 1 miljoen tokens.[17](#ref-17), [82](#ref-82) **GPT-4.1** is het vlaggenschipmodel, geoptimaliseerd voor complexe taken en uitmuntend in softwareontwikkeling, onderzoek en agentische workflows.[80](#ref-80), [84](#ref-84) Het model toont aanzienlijke verbeteringen in real-world software engineering en instructienauwkeurigheid.[80](#ref-80), [82](#ref-82), [84](#ref-84) **GPT-4.1 mini** biedt bijna dezelfde mogelijkheden als het volledige model, maar met lagere latency en kosten, waardoor het een gebalanceerde optie is voor diverse toepassingen.[80](#ref-80), [84](#ref-84) **GPT-4.1 nano** is het snelste en meest kostenefficiënte model in deze serie, ideaal voor taken zoals classificatie en autocompletion.[80](#ref-80), [84](#ref-84)

### Gespecialiseerde Modellen en Updates

[Inhoudsopgave](#table-of-contents)

Naast deze primaire modellen heeft OpenAI ook diverse gespecialiseerde versies en updates uitgebracht, zoals gpt-4o-search-preview en gpt-4o-mini-search-preview voor websearch, computer-use-preview voor specifieke toolgebruik, en audio-gerelateerde modellen zoals gpt-4o-audio-preview en gpt-4o mini TTS.[6](#ref-6), [9](#ref-9) Deze op maat gemaakte modellen illustreren de strategie van OpenAI om een breed scala aan LLM's te bieden voor uiteenlopende toepassingsbehoeften.

### Tabel: OpenAI LLM Gebieden van Uitmuntendheid

[Inhoudsopgave](#table-of-contents)

| OpenAI LLM Naam | Gebieden van Uitmuntendheid |
| :------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| GPT-4o | Realtime multimodale interactie, snelle responstijden, verbeterde prestaties in niet-Engelse talen |
| GPT-4o mini | Kostenefficiënte intelligentie, sterke prestaties in wiskunde, programmeren en visueel redeneren voor zijn formaat |
| o1 | Complexe redenatie, oplossen van moeilijke problemen in wetenschap, programmeren en wiskunde, cybersecurity |
| o1-mini | Snellere en kostenefficiëntere redenatie voor STEM-taken, vooral wiskunde en programmeren |
| o3 | State-of-the-art redenatie, uitmuntend in programmeren, wiskunde, wetenschap en visuele perceptie |
| o4-mini | Snelle en efficiënte redenatie, best-in-class prestaties op AIME voor zijn formaat, sterk in wiskunde, programmeren en visuele analyse |
| GPT-4.5 | Brede kennis, verbeterd vermogen om gebruikersintentie te volgen, sterk in schrijven en creatieve taken, feitelijke nauwkeurigheid |
| GPT-4.1 | Grote vooruitgang in programmeren, instructievolging en lang-contextbegrip, multi-document Q&A, redeneren op complexe visuele data |
| GPT-4.1 mini | Gebalanceerde intelligentie, snelheid en kosten, instructievolging, beeldgebaseerd redeneren |
| GPT-4.1 nano | Snelheid, kostenefficiëntie, classificatie, autocompletion |
| gpt-4o-search-preview | Websearch in Chat Completions |
| gpt-4o-mini-search-preview | Snel, betaalbaar klein model voor websearch |
| computer-use-preview | Gespecialiseerd model voor computergebruik |
| GPT-4o Audio | Audio-invoer en -uitvoer |
| GPT-4o mini Audio | Kleinere model met audio-invoer en -uitvoer |
| GPT-4o Realtime | Realtime tekst- en audio-invoer en -uitvoer |
| GPT-4o mini Realtime | Kleinere realtime model voor tekst- en audio-invoer en -uitvoer |
| GPT-4o mini TTS | Tekst-naar-spraak |
| GPT-4o Transcribe | Spraak-naar-tekst |
| GPT-4o mini Transcribe | Spraak-naar-tekst |
| o1-preview | Vroege preview van het volledige o1-model, aanpak van complexe problemen die brede algemene kennis vereisen |
| o3-mini | Kostenefficiënte redenatie, superieure prestaties bij lage latency/kosten, verbeterde ontwikkelaarsfuncties, sterk in wetenschap, wiskunde en programmeren |
| o3-pro | Verbeterde versie van o3 |
| o3-mini-high | Variant van o3-mini met hogere redeneerinspanning |
| o3-mini-medium | Variant van o3-mini met gemiddelde redeneerinspanning |
| o1-pro | Versie van o1 met meer rekenkracht voor betere antwoorden |
| gpt-4o-2024-08-06 | Gestructureerde output, tekst, beeldverwerking |
| gpt-4o-2024-11-20 | Gestructureerde output, tekst, beeldverwerking, verbeterde nauwkeurigheid en responsiviteit, superieure prestaties in niet-Engelse talen en visuele taken, verbeterde creatieve mogelijkheden |
| gpt-4o-2024-05-13 | Tekst, beeldverwerking, verbeterde nauwkeurigheid en responsiviteit, superieure prestaties in niet-Engelse talen en visuele taken |
| o3 (2025-04-16) | Verbeterde redeneercapaciteiten, tekst, beeldverwerking |
| o4-mini (2025-04-16) | Verbeterde redeneercapaciteiten, tekst, beeldverwerking |
| o3-mini (2025-01-31) | Verbeterde redeneercapaciteiten, alleen tekstverwerking |
| o1 (2024-12-17) | Verbeterde redeneercapaciteiten, tekst, beeldverwerking |
| o1-preview (2024-09-12) | Oudere previewversie |
| o1-mini (2024-09-12) | Snellere en kostenefficiëntere optie in de o1-serie, ideaal voor programmeertaken die snelheid en lagere resourceconsumptie vereisen |

## 3\. Vergelijkende Analyse met Alternatieve LLM's

[Inhoudsopgave](#table-of-contents)

Het LLM-landschap reikt verder dan OpenAI, met verschillende organisaties die sinds mei 2024 zeer competitieve modellen hebben uitgebracht. Deze alternatieve LLM's evenaren of overtreffen vaak de modellen van OpenAI op specifieke gebieden, wat de snelle vooruitgang en diverse benaderingen binnen het veld onderstreept.

### Claude 3.7 Sonnet (Anthropic)

[Inhoudsopgave](#table-of-contents)

**Claude 3.7 Sonnet** van Anthropic, uitgebracht in februari 2025 [61](#ref-61), [85](#ref-85), wordt gepositioneerd als een zeer intelligent model met state-of-the-art mogelijkheden voor programmeren en aanzienlijke verbeteringen in contentgeneratie, data-analyse en planning.[85](#ref-85), [86](#ref-86), [87](#ref-87) Benchmarks tonen aan dat Claude 3.7 Sonnet uitblinkt in instructievolging en hoge scores behaalt op IFEval.[63](#ref-63) Het model presteert ook sterk bij programmeertaken, met competitieve scores op de Aider polyglot benchmark.[62](#ref-62) Anthropic heeft aangegeven dat Sonnet is ontworpen om GPT-4o te overtreffen, waardoor het een directe concurrent is qua intelligentie en veelzijdigheid.[2](#ref-2)

### Grok-3 (xAI)

[Inhoudsopgave](#table-of-contents)

**Grok-3**, ontwikkeld door xAI en onthuld in februari 2025 [61](#ref-61), [64](#ref-64), vertegenwoordigt een aanzienlijke sprong in redeneercapaciteiten, met tien keer meer rekenkracht dan zijn voorganger, Grok-2.[88](#ref-88), [89](#ref-89) Getraind op xAI's Colossus-supercluster, laat Grok-3 sterke prestaties zien in STEM-domeinen, met hoge nauwkeurigheid op de AIME 2025 wiskunde (93,3%) en GPQA (84,6%) graduate-level redeneerbenchmarks.[64](#ref-64), [65](#ref-65), [88](#ref-88) Bij programmeren scoort het indrukwekkend op LiveCodeBench (79,4%).[64](#ref-64), [65](#ref-65), [88](#ref-88) Grok-3 heeft een "Think"-modus waarmee het antwoorden kan verfijnen via test-time computation, wat de nauwkeurigheid bij complexe analytische taken vergroot.[64](#ref-64), [88](#ref-88), [90](#ref-90) De prestaties op de LMSYS Arena leaderboard zijn ook opmerkelijk, waarbij het modellen als GPT-4o en Claude 3.5 Sonnet overtreft.[89](#ref-89), [91](#ref-91)

### Gemini 2.0 (Google DeepMind)

[Inhoudsopgave](#table-of-contents)

Google DeepMind blijft innoveren met de **Gemini 2.0**-familie van modellen. Sinds mei 2024 zijn verschillende varianten uitgebracht of bijgewerkt, waaronder **Gemini 2.0 Pro**, **Gemini 2.0 Flash** en **Gemini 2.0 Flash-Lite**.[2](#ref-2), [3](#ref-3), [4](#ref-4), [61](#ref-61), [66](#ref-66), [92](#ref-92), [93](#ref-93), [94](#ref-94), [95](#ref-95), [96](#ref-96) Deze modellen zijn multimodaal, kunnen tekst, afbeeldingen, audio en video verwerken (met verschillende ondersteuning per model) en tekst genereren.[2](#ref-2), [92](#ref-92) Een belangrijk voordeel van de Gemini 2.0-familie is het grote contextvenster, waarbij Flash en Pro tot 1 miljoen tokens ondersteunen.[3](#ref-3), [92](#ref-92), [93](#ref-93) Gemini 2.0 Pro wordt beschouwd als het beste model van Google tot nu toe voor programmeren en complexe prompts.[94](#ref-94) Benchmarks tonen aan dat Gemini 2.0 Flash beter presteert dan 1.5 Flash op het gebied van redenatie, multimodale taken, wiskunde en feitelijkheid.[93](#ref-93), [94](#ref-94) Gemini 2.0 Flash-Lite is geoptimaliseerd voor kostenefficiëntie en lage latency, met verbeterde prestaties op SimpleQA en BirdSQL.[94](#ref-94) Bij programmeren presteert Gemini 2.0 Flash sterk op LiveBench.[66](#ref-66)

### DeepSeek R1 en V3 (DeepSeek AI)

[Inhoudsopgave](#table-of-contents)

**DeepSeek AI** is een sterke speler geworden, vooral met de **DeepSeek R1** en **DeepSeek V3** modellen.[4](#ref-4), [61](#ref-61), [97](#ref-97), [98](#ref-98), [99](#ref-99), [100](#ref-100), [101](#ref-101), [102](#ref-102) DeepSeek R1, uitgebracht in januari 2025, is een 671B parameter Mixture-of-Experts (MoE) model gericht op redeneercapaciteiten, getraind via grootschalige reinforcement learning.[98](#ref-98), [99](#ref-99) Het model behaalt prestaties vergelijkbaar met OpenAI-o1 op het gebied van wiskunde (MATH-500: 97,3%), programmeren (Codeforces: 96,3% percentiel) en redeneertaken.[97](#ref-97), [98](#ref-98) DeepSeek R1 is ontworpen voor stapsgewijze redenatie, waardoor het geschikt is voor onderzoek en analyse.[100](#ref-100), [102](#ref-102) DeepSeek V3, uitgebracht in december 2024, is ook een 671B parameter MoE model, maar geoptimaliseerd voor bredere prestaties op meerdere NLP-benchmarks met behoud van efficiënte trainingskosten.[97](#ref-97), [98](#ref-98) Het model bevat redeneercapaciteiten gedistilleerd uit DeepSeek R1 en ondersteunt een 128K contextvenster.[98](#ref-98), [99](#ref-99) Opvallend is dat DeepSeek V3 aanzienlijk kostenefficiënter is dan DeepSeek R1 voor API-gebruik.[98](#ref-98), [99](#ref-99)

### Mistral Large 2 (Mistral AI)

[Inhoudsopgave](#table-of-contents)

**Mistral AI** heeft zijn modellenreeks verder ontwikkeld, met **Mistral Large 2** uitgebracht in juli 2024.[4](#ref-4), [61](#ref-61), [103](#ref-103), [104](#ref-104), [105](#ref-105), [106](#ref-106), [107](#ref-107) Dit model beschikt over topklasse redeneercapaciteiten en blinkt uit in geavanceerde redenatie, meertalige taken, wiskunde en codegeneratie.[105](#ref-105) Het heeft een contextvenster van 128K tokens en presteert sterk op de MMLU-benchmark (84,0% in een 5-shot scenario).[104](#ref-104), [107](#ref-107) Mistral Large 2 staat ook bekend om zijn kostenefficiëntie ten opzichte van oudere modellen zoals GPT-4 32K.[107](#ref-107)

### Llama 3.1 (Meta AI)

[Inhoudsopgave](#table-of-contents)

Meta AI heeft **Llama 3.1** uitgebracht in juli 2024, voortbouwend op de sterke punten van eerdere modellen met verbeterde NLP-prestaties en beter contextueel begrip.[4](#ref-4), [61](#ref-61), [108](#ref-108), [109](#ref-109), [110](#ref-110), [111](#ref-111), [112](#ref-112), [113](#ref-113) De Llama 3.1-familie omvat modellen met 8B, 70B en 405B parameters, waarbij het 405B-model uitmuntende prestaties levert op een breed scala aan industriestandaard benchmarks, vaak gelijk of beter dan GPT-4 in sommige tests.[113](#ref-113) Llama 3.1 405B behaalt hoge scores op MMLU (88,6%), HumanEval (89,0%) en GSM8K (96,8%).[109](#ref-109), [111](#ref-111), [112](#ref-112) Het model blinkt ook uit in lang-contexttaken met een contextvenster van 128K tokens.[111](#ref-111)

### Phi-3 (Microsoft)

[Inhoudsopgave](#table-of-contents)

Microsoft heeft sinds april 2024 de **Phi-3**-familie van Small Language Models (SLMs) geïntroduceerd, waaronder modellen als Phi-3 mini, small, medium en de Phi-3.5-serie.[4](#ref-4), [61](#ref-61), [114](#ref-114), [115](#ref-115), [116](#ref-116), [117](#ref-117), [118](#ref-118) Deze modellen zijn ontworpen om zeer capabel en kostenefficiënt te zijn, en presteren vaak beter dan modellen van vergelijkbare of grotere omvang op diverse benchmarks voor taal, redenatie, programmeren en wiskunde.[116](#ref-116) Phi-3 mini, met 3,8 miljard parameters, behaalt prestaties vergelijkbaar met modellen als Mixtral 8x7B en GPT-3.5 op benchmarks als MMLU (69%) en MT-bench (8,38).[117](#ref-117), [118](#ref-118) De Phi-3.5-serie verbetert de mogelijkheden verder, met Phi-3.5-mini die een contextlengte van 128K ondersteunt en verbeterde meertalige ondersteuning biedt.[116](#ref-116) Phi-3.5-MoE, met 6,6B actieve parameters, levert hoge prestaties in taalbegrip, wiskunde en redenatie, en overtreft vaak grotere modellen.[116](#ref-116)

### Amazon Nova (Amazon)

[Inhoudsopgave](#table-of-contents)

Amazon introduceerde zijn **Amazon Nova**-modellen (Pro, Micro, Lite) op AWS re:Invent in december 2024.[4](#ref-4), [61](#ref-61), [27](#ref-27) Deze modellen worden gepresenteerd als kostenefficiënte alternatieven voor de modellen van OpenAI, vooral bij retrieval-augmented generation-taken. Hoewel GPT-4o een klein voordeel in nauwkeurigheid liet zien ten opzichte van Amazon Nova Pro op een subset van de CRAG-benchmarkdataset, presteerde Amazon Nova Pro efficiënter, met 97% snellere werking en 65,26% meer kostenefficiëntie.[27](#ref-27) Amazon Nova Micro en Amazon Nova Lite lieten ook competitieve nauwkeurigheid en kostenefficiëntie zien vergeleken met GPT-4o-mini.[27](#ref-27)

## 4\. Samenvattende Tabel van OpenAI en Alternatieve LLM Benchmarks

[Inhoudsopgave](#table-of-contents)

| Modelnaam | Organisatie | MMLU (%) | HumanEval (%) | AIME (%) | GPQA (%) | SWE-bench (%) | Contextvenster (Tokens) | Approx. Parameters (B) | Bron(nen) |
| :--------------------- | :---------------- | :------- | :------------ | :------- | :------- | :------------ | :---------------------- | :----------------------- | :------------------------- |
| GPT-4o | OpenAI | 88.7 | 90.2 | 9.3 | 53.6 | 33.2 | 128,000 | \~1.8T | [12](#ref-12), [32](#ref-32), [71](#ref-71) |
| Claude 3.7 Sonnet | Anthropic | N/B | N/B | N/B | N/B | N/B | 200,000 | \~175-200 | [2](#ref-2), [86](#ref-86) |
| Grok-3 | xAI | 92.7 | 86.5 | 93.3 | 84.6 | N/B | 128,000 | 2.7T | [88](#ref-88), [91](#ref-91) |
| Gemini 2.0 Pro | Google DeepMind | 81.9 | 71.9 | N/B | N/B | N/B | 2,097,152 | Onbekend | [2](#ref-2), [32](#ref-32) |
| DeepSeek R1 | DeepSeek | 90.8 | N/B | 79.8 | 71.5 | N/B | 128,000 | 671 | [97](#ref-97), [98](#ref-98) |
| Mistral Large 2 | Mistral AI | 84.0 | N/B | N/B | N/B | N/B | 128,000 | 123 | [103](#ref-103), [104](#ref-104) |
| Llama 3.1 (405B) | Meta AI | 88.6 | 89.0 | 96.8 | 51.1 | 88.6 | 128,000 | 405 | [109](#ref-109), [111](#ref-111), [112](#ref-112) |
| Phi-3 Medium | Microsoft | 78.0 | N/B | N/B | N/B | N/B | 128,000 | 14 | [117](#ref-117) |
| Amazon Nova Pro | Amazon | 51.5 | N/B | N/B | N/B | N/B | 300,000 | Onbekend | [27](#ref-27) |
| GPT-4.1 | OpenAI | N/B | 54.6 | N/B | N/B | 54.6 | 1,000,000 | Onbekend | [17](#ref-17), [80](#ref-80) |
| o3 | OpenAI | 91.6 | N/B | 96.7 | 87.7 | 71.7 | 200,000 | Onbekend | [5](#ref-5), [43](#ref-43) |
| o4-mini | OpenAI | 93.4 | N/B | 99.5 | 81.4 | 68.1 | 200,000 | Onbekend | [5](#ref-5) |
| GPT-4.5 | OpenAI | 85.1 | 32.6 | 36.7 | 71.4 | 38.0 | 128,000 | Onbekend | [71](#ref-71) |

## 5\. Conclusie

[Inhoudsopgave](#table-of-contents)

De analyse van Grote Taalmodellen die sinds mei 2024 zijn uitgebracht, laat een periode van intense innovatie en snelle vooruitgang binnen het veld zien. OpenAI blijft een dominante speler, met een divers aanbod aan modellen, waaronder het vlaggenschip multimodale GPT-4o, de kostenefficiënte GPT-4o mini, de redenatiegerichte o-serie (o1, o3, o4-mini) en de krachtige GPT-4.1-familie. Deze modellen tonen aanzienlijke vooruitgang op het gebied van multimodaliteit, redeneercapaciteiten en prestaties op diverse benchmarks, en bedienen een breed spectrum aan toepassingen en gebruikersbehoeften.

Toch is het LLM-landschap steeds competitiever. Alternatieve LLM's van organisaties als Anthropic (Claude 3.7 Sonnet), xAI (Grok-3), Google DeepMind (Gemini 2.0), DeepSeek (DeepSeek R1, V3), Mistral AI (Mistral Large 2), Meta AI (Llama 3.1), Microsoft (Phi-3) en Amazon (Amazon Nova) zijn sterke concurrenten geworden, die vaak de modellen van OpenAI evenaren of overtreffen op specifieke gebieden. Claude 3.7 Sonnet blinkt uit in instructievolging en programmeren. Grok-3 presteert superieur in wiskunde, wetenschap en redenatie. Gemini 2.0-modellen bieden grote contextvensters en sterke programmeermogelijkheden. DeepSeek R1 excelleert in verklaarbare redenatie en STEM-taken. Mistral Large 2 biedt robuuste redenatie en meertalige mogelijkheden. Llama 3.1 laat indrukwekkende resultaten zien op een breed scala aan benchmarks. Phi-3-modellen bieden opmerkelijke mogelijkheden voor hun compacte formaat. Amazon Nova-modellen bieden kostenefficiënte oplossingen voor specifieke toepassingen.

De huidige stand van het LLM-landschap wordt gekenmerkt door een sterke focus op het verbeteren van redeneercapaciteiten, het uitbreiden van multimodale functionaliteiten, het verbeteren van efficiëntie en kosteneffectiviteit, en het ondersteunen van langere contextvensters. Het snelle innovatietempo zorgt ervoor dat er voortdurend nieuwe modellen met steeds geavanceerdere mogelijkheden verschijnen. Hoewel OpenAI een leider blijft, onderstrepen de concurrentievoordelen van alternatieve LLM's het belang van het afstemmen van de modelkeuze op specifieke gebruikssituaties. De optimale keuze hangt vaak af van de taak, gewenste prestatiekenmerken en budgettaire overwegingen, waardoor een grondig inzicht in de sterke en zwakke punten van elk model essentieel is voor weloverwogen beslissingen.

## 6\. References

[Table of Contents](#table-of-contents)

<!-- De referentiesectie blijft onvertaald -->

## 6\. References

[Table of Contents](#table-of-contents)

<a id="ref-1"></a>
1.  OpenAI. (2025, February 27). *Introducing GPT-4.5*. [https://openai.com/index/introducing-gpt-4-5/](https://openai.com/index/introducing-gpt-4-5/)
<a id="ref-2"></a>
2.  Anthropic. (2025, February 24). *Claude 3.7 Sonnet and Claude Code*. [https://www.anthropic.com/news/claude-3-7-sonnet](https://www.anthropic.com/news/claude-3-7-sonnet)
<a id="ref-3"></a>
3.  Google DeepMind. (n.d.). *Gemini 2.5: Models*. [https://deepmind.google/technologies/gemini/flash-thinking/](https://www.google.com/search?q=https://deepmind.google/technologies/gemini/flash-thinking/)
<a id="ref-4"></a>
4.  Exploding Topics. (2025, February). *Top LLMs in February 2025*. [https://explodingtopics.com/blog/list-of-llms](https://explodingtopics.com/blog/list-of-llms)
<a id="ref-5"></a>
5.  OpenAI. (2025, April 16). *Introducing o3 and o4-mini*. [https://openai.com/index/introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/)
<a id="ref-6"></a>
6.  OpenAI. (n.d.). *Models*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-7"></a>
7.  PYMNTS. (2025, April 18). *OpenAI Says Its Latest Models Bring More Capable AI Agents to Business*. [https://www.pymnts.com/artificial-intelligence-2/2025/openai-says-its-latest-models-bring-more-capable-ai-agents-to-business/](https://www.pymnts.com/artificial-intelligence-2/2025/openai-says-its-latest-models-bring-more-capable-ai-agents-to-business/)
<a id="ref-8"></a>
8.  Microsoft Azure. (2025, April). *Azure OpenAI Service Models overview*. [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
<a id="ref-9"></a>
9.  OpenAI. (n.d.). *Model index for the OpenAI API*. [https://model-spec.openai.com/](https://model-spec.openai.com/)
<a id="ref-10"></a>
10. OpenAI. (2025, April 14). *GPT-4.1*. [https://openai.com/index/gpt-4-1/](https://openai.com/index/gpt-4-1/)
<a id="ref-11"></a>
11. OpenAI. (2025, February 27). *OpenAI GPT-4.5 System Card*. [https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf](https://cdn.openai.com/gpt-4-5-system-card-2272025.pdf)
<a id="ref-12"></a>
12. OpenAI. (2024, May 13). *Hello GPT-4o*. [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)
<a id="ref-13"></a>
13. Amazon Web Services. (2025, April 17). *Benchmarking Amazon Nova and GPT-4o Models with FloTorch*. [https://aws.amazon.com/blogs/machine-learning/benchmarking-amazon-nova-and-gpt-4o-models-with-flotorch/](https://aws.amazon.com/blogs/machine-learning/benchmarking-amazon-nova-and-gpt-4o-models-with-flotorch/)
<a id="ref-14"></a>
14. OpenAI. (2024, July 18). *GPT-4o mini: Advancing cost-efficient intelligence*. [https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
<a id="ref-15"></a>
15. Microsoft Azure. (2024, May 14). *OpenAI’s fastest model, GPT-4o mini, is now available on Azure AI*. [https://azure.microsoft.com/en-us/blog/openais-fastest-model-gpt-4o-mini-is-now-available-on-azure-ai/](https://azure.microsoft.com/en-us/blog/openais-fastest-model-gpt-4o-mini-is-now-available-on-azure-ai/)
<a id="ref-16"></a>
16. Box AI. (2025, April 15). *First Look: GPT-4.1 Now Available in Box AI Studio*. [https://blog.box.com/first-look-gpt-4\_1-now-available-box-ai-studio](https://blog.box.com/first-look-gpt-4_1-now-available-box-ai-studio)
<a id="ref-17"></a>
17. OpenAI. (2025, April 14). *GPT-4.1 Benchmark Performance Compared to Leading Models*. [https://openai.com/index/gpt-4-1/](https://openai.com/index/gpt-4-1/)
<a id="ref-18"></a>
18. OpenAI. (2024, May 13). *GPT-4o System Card*. [https://openai.com/index/gpt-4o-system-card/](https://openai.com/index/gpt-4o-system-card/)
<a id="ref-19"></a>
19. OpenAI. (2024, August 15). *Updates to GPT-4o in ChatGPT*. [https://help.openai.com/en/articles/9624314-model-release-notes](https://help.openai.com/en/articles/9624314-model-release-notes)
<a id="ref-20"></a>
20. OpenAI. (2024, August 6). *Introducing Structured Outputs*. [https://openai.com/blog/function-calling-and-other-api-updates](https://openai.com/blog/function-calling-and-other-api-updates)
<a id="ref-21"></a>
21. OpenAI. (2024, December 17). *Introducing our next generation audio models*. [https://openai.com/index/introducing-our-next-generation-audio-models/](https://openai.com/index/introducing-our-next-generation-audio-models/)
<a id="ref-22"></a>
22. GeeksforGeeks. (2024, May 14). *GPT-4o: OpenAI’s New Multimodal Model*. [https://www.geeksforgeeks.org/gpt-4o-openais-new-multimodal-model/](https://www.google.com/search?q=https://www.geeksforgeeks.org/gpt-4o-openais-new-multimodal-model/)
<a id="ref-23"></a>
23. OpenAI. (2024, May 13). *Introducing GPT-4o and more tools to ChatGPT free users*. [https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/](https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/)
<a id="ref-24"></a>
24. Unthread. (2024, May 14). *The 5 Coolest Features of GPT4o*. [https://unthread.io/blog/the-5-coolest-features-of-gpt4o/](https://unthread.io/blog/the-5-coolest-features-of-gpt4o/)
<a id="ref-25"></a>
25. IBM. (2024, May 15). *What is GPT-4o? Understanding OpenAI’s Newest Model*. [https://www.ibm.com/think/topics/gpt-4o](https://www.ibm.com/think/topics/gpt-4o)
<a id="ref-26"></a>
26. TechTarget. (2024, May). *GPT-4o explained: Everything you need to know*.([https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know](https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know))
<a id="ref-27"></a>
27. FloTorch. (2024, December 3). *Benchmarking Amazon Nova and GPT-4o Models with FloTorch*. [https://aws.amazon.com/blogs/machine-learning/benchmarking-amazon-nova-and-gpt-4o-models-with-flotorch/](https://aws.amazon.com/blogs/machine-learning/benchmarking-amazon-nova-and-gpt-4o-models-with-flotorch/)
<a id="ref-28"></a>
28. OpenAI. (n.d.). *Changelog*. [https://platform.openai.com/docs/changelog](https://platform.openai.com/docs/changelog)
<a id="ref-29"></a>
29. DataCamp. (2025, April 15). *A Guide to GPT-4.1*. [https://www.datacamp.com/blog/gpt-4-1](https://www.datacamp.com/blog/gpt-4-1)
<a id="ref-30"></a>
30. OpenAI. (2024, August 6). *Introducing gpt-4o-2024-08-06*. [https://openai.com/blog/gpt-4o-and-other-updates](https://www.google.com/search?q=https://openai.com/blog/gpt-4o-and-other-updates)
<a id="ref-31"></a>
31. OpenAI. (2024, September 12). *Introducing OpenAI o1*. [https://openai.com/index/introducing-openai-o1/](https://www.google.com/search?q=https://openai.com/index/introducing-openai-o1/)
<a id="ref-32"></a>
32. Wielded. (2024, May 15). *GPT-4o Benchmark: Detailed Comparison with Claude and Gemini*. [https://wielded.com/blog/gpt-4o-benchmark-detailed-comparison-with-claude-and-gemini](https://wielded.com/blog/gpt-4o-benchmark-detailed-comparison-with-claude-and-gemini)
<a id="ref-33"></a>
33. Microsoft Azure. (2024, December 18). *Azure OpenAI Service December 2024 updates*. [https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new](https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new)
<a id="ref-34"></a>
34. OpenAI. (2024, July 18). *GPT-4o mini: Advancing cost-efficient intelligence*. [https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
<a id="ref-35"></a>
35. Leanware. (2025, February 28). *Grok 3 vs GPT Models Comparison*. [https://www.leanware.co/insights/grok-3-vs-gpt-models-comparison](https://www.leanware.co/insights/grok-3-vs-gpt-models-comparison)
<a id="ref-36"></a>
36. OpenAI Developer Community. (2025, March 14). *GPT-4.5 is Incredible, but Critical Improvements Needed for Deep User Engagement*. [https://community.openai.com/t/gpt-4-5-is-incredible-but-critical-improvements-needed-for-deep-user-engagement/1143056](https://community.openai.com/t/gpt-4-5-is-incredible-but-critical-improvements-needed-for-deep-user-engagement/1143056)
<a id="ref-37"></a>
37. YouTube. (2024, May 14). *GPT-4o: The New OpenAI Model Explained*. [https://www.youtube.com/watch?v=irYyK-CqcVI](https://www.youtube.com/watch?v=irYyK-CqcVI)
<a id="ref-38"></a>
38. Daily.dev. (2024, May 14). *OpenAI's GPT-4o: Everything You Need to Know in One Place*. [https://daily.dev/blog/openais-gpt-4o-everything-you-need-to-know-in-one-place](https://daily.dev/blog/openais-gpt-4o-everything-you-need-to-know-in-one-place)
<a id="ref-39"></a>
39. Codingscape. (2025, February 28). *Most Powerful LLMs (Large Language Models)*. [https://codingscape.com/blog/most-powerful-llms-large-language-models](https://codingscape.com/blog/most-powerful-llms-large-language-models)
<a id="ref-40"></a>
40. GeeksforGeeks. (2024, May 15). *GPT-4o Mini: A Comprehensive Overview*. [https://www.geeksforgeeks.org/deepseek-r1-vs-deepseek-v3/](https://www.geeksforgeeks.org/deepseek-r1-vs-deepseek-v3/)
<a id="ref-41"></a>
41. OpenAI API. (n.d.). *GPT-4o*. [https://platform.openai.com/docs/models/gpt-4o](https://platform.openai.com/docs/models/gpt-4o)
<a id="ref-42"></a>
42. Artificial Analysis. (2024, November). *Mistral Large 2 (Nov '24): Intelligence, Performance & Price Analysis*. [https://artificialanalysis.ai/models/mistral-large-2](https://artificialanalysis.ai/models/mistral-large-2)
<a id="ref-43"></a>
43. OpenAI. (2025, April 16). *Introducing o3 and o4-mini*. [https://openai.com/index/introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/)
<a id="ref-44"></a>
44. OpenAI. (n.d.). *Models*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-45"></a>
45. Analytics Vidhya. (2025, February 28). *OpenAI GPT-4.5*. [https://www.analyticsvidhya.com/blog/2025/02/openai-gpt-4-5/](https://www.analyticsvidhya.com/blog/2025/02/openai-gpt-4-5/)
<a id="ref-46"></a>
46. Artificial Analysis. (2024, November). *GPT-4o (Nov '24): Intelligence, Performance & Price Analysis*. [https://artificialanalysis.ai/models/gpt-4o](https://artificialanalysis.ai/models/gpt-4o)
<a id="ref-47"></a>
47. ZDNet. (2025, April 16). *OpenAI just dropped new o3 and o4-mini reasoning AI models and a surprise agent*. [https://www.zdnet.com/article/openai-just-dropped-new-o3-and-o4-mini-reasoning-ai-models-and-a-surprise-agent/](https://www.zdnet.com/article/openai-just-dropped-new-o3-and-o4-mini-reasoning-ai-models-and-a-surprise-agent/)
<a id="ref-48"></a>
48. OpenAI API. (n.d.). *GPT-4o mini*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-49"></a>
49. Reddit. (n.d.). *Claude 3.7 Sonnet's results on six independent benchmarks : ClaudeAI*. [https://www.reddit.com/r/ClaudeAI/comments/1iz3umm/claude\_37\_sonnets\_results\_on\_six\_independent/](https://www.reddit.com/r/ClaudeAI/comments/1iz3umm/claude_37_sonnets_results_on_six_independent/)
<a id="ref-50"></a>
50. Microsoft Azure. (2024, December 17). *Azure OpenAI Service December 2024 updates*. [https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new](https://learn.microsoft.com/en-us/azure/ai-services/openai/whats-new)
<a id="ref-51"></a>
51. OpenAI. (2025, April 16). *Introducing o3 and o4-mini*. [https://openai.com/index/introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/)
<a id="ref-52"></a>
52. Intento. (2024, May 14). *May 2024: Integrations with LLMs from Anthropic, Google, and OpenAI, and more\!*. [https://inten.to/blog/may-2024-integrations-with-llms-from-anthropic-google-and-openai-and-more/](https://inten.to/blog/may-2024-integrations-with-llms-from-anthropic-google-and-openai-and-more/)
<a id="ref-53"></a>
53. xAI. (2025, February 17). *Grok 3 Beta — The Age of Reasoning Agents*. [https://x.ai/news/grok-3](https://x.ai/news/grok-3)
<a id="ref-54"></a>
54. xAI. (2025, February 17). *Grok 3 Beta — The Age of Reasoning Agents*. [https://x.ai/news/grok-3](https://x.ai/news/grok-3)
<a id="ref-55"></a>
55. BentoML. (2025, March 27). *The Complete Guide to DeepSeek Models: From V3 to R1 and Beyond*. [https://www.bentoml.com/blog/the-complete-guide-to-deepseek-models-from-v3-to-r1-and-beyond](https://www.bentoml.com/blog/the-complete-guide-to-deepseek-models-from-v3-to-r1-and-beyond)
<a id="ref-56"></a>
56. DataCamp. (2024, December 6). *OpenAI o1: A New Era of Reasoning in AI*. [https://www.datacamp.com/blog/open-ai-o1](https://www.datacamp.com/blog/open-ai-o1)
<a id="ref-57"></a>
57. Reddit. (n.d.). *the latest gpt-4o seems to be worse in some benchmarks. : singularity*. [https://www.reddit.com/r/singularity/comments/1gwaa1c/the\_latest\_gpt4o\_seems\_to\_be\_worse\_in\_some/](https://www.reddit.com/r/singularity/comments/1gwaa1c/the_latest_gpt4o_seems_to_be_worse_in_some/)
<a id="ref-58"></a>
58. OpenAI. (2024, September 12). *Introducing OpenAI o1-mini: Advancing cost-efficient reasoning*. [https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)
<a id="ref-59"></a>
59. InfoQ. (2025, February 7). *Google Expands Gemini 2 Family with Flash-Lite and Pro Models*. [https://www.infoq.com/news/2025/02/gemini-2-flash-lite-pro-models/](https://www.infoq.com/news/2025/02/gemini-2-flash-lite-pro-models/)
<a id="ref-60"></a>
60. OpenAI API. (n.d.). *o1-mini*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-61"></a>
61. Zapier. (2025, February 28). *The best LLMs in 2025*. [https://zapier.com/blog/best-llm/](https://zapier.com/blog/best-llm/)
<a id="ref-62"></a>
62. DataOps Labs. (2025, March 28). *DeepSeek R1 vs DeepSeek V3*. [https://blog.dataopslabs.com/deepseek-r1-vs-deepseek-v3](https://blog.dataopslabs.com/deepseek-r1-vs-deepseek-v3)
<a id="ref-63"></a>
63. Spheron. (2024, April 15). *Llama 3.1 In-Depth Analysis: Cutting Through the Noise*. [https://blog.spheron.network/llama-31-in-depth-analysis-cutting-through-the-noise](https://blog.spheron.network/llama-31-in-depth-analysis-cutting-through-the-noise)
<a id="ref-64"></a>
64. DocsBot AI. (n.d.). *Compare DeepSeek-R1 vs DeepSeek-V3*. [https://docsbot.ai/models/compare/deepseek-r1/deepseek-v3](https://docsbot.ai/models/compare/deepseek-r1/deepseek-v3)
<a id="ref-65"></a>
65. xAI. (2025, February 17). *Grok-3*. [https://x.ai/news/grok-3](https://x.ai/news/grok-3)
<a id="ref-66"></a>
66. Reddit. (n.d.). *Gemini 2.0 Flash vs 1.5 Pro vs 2.0 Flash-Lite for coding? : Bard*.([https://www.reddit.com/r/Bard/comments/1j6ai3s/gemini\_20\_flash\_vs\_15\_pro\_vs\_20\_flashlite\_for/](https://www.reddit.com/r/Bard/comments/1j6ai3s/gemini_20_flash_vs_15_pro_vs_20_flashlite_for/))
<a id="ref-67"></a>
67. OpenAI. (2025, January 31). *Introducing OpenAI o3-mini*. [https://openai.com/index/openai-o3-mini/](https://openai.com/index/openai-o3-mini/)
<a id="ref-68"></a>
68. OpenAI. (2025, April 16). *Introducing o3 and o4-mini*. [https://openai.com/index/introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/)
<a id="ref-69"></a>
69. Gaper. (2024, July 23). *Meta’s New Llama 3.1*. [https://gaper.io/metas-new-llama-3-1/](https://gaper.io/metas-new-llama-3-1/)
<a id="ref-70"></a>
70. Hydrox AI. (2024, September 13). *Evaluating OpenAI's o1-mini and GPT-4o mini - Advances and Areas for Improvement*. [https://www.hydrox.ai/blogs/evaluating-openais-o1-mini-and-gpt-4o-mini---advances-and-areas-for-improvement](https://www.hydrox.ai/blogs/evaluating-openais-o1-mini-and-gpt-4o-mini---advances-and-areas-for-improvement)
<a id="ref-71"></a>
71. Reddit. (n.d.). *GPT-4.5 Benchmark Performance : singularity*. [https://www.reddit.com/r/singularity/comments/1izp75f/gpt45\_benchmark\_performance/](https://www.reddit.com/r/singularity/comments/1izp75f/gpt45_benchmark_performance/)
<a id="ref-72"></a>
72. OpenAI. (n.d.). *OpenAI*. [https://openai.com/](https://openai.com/)
<a id="ref-73"></a>
73. OpenAI. (n.d.). *o1*. [https://openai.com/o1/](https://openai.com/o1/)
<a id="ref-74"></a>
74. DocsBot AI. (n.d.). *Compare DeepSeek-V3 vs DeepSeek-R1*. [https://docsbot.ai/models/compare/deepseek-v3/deepseek-r1](https://docsbot.ai/models/compare/deepseek-v3/deepseek-r1)
<a id="ref-75"></a>
75. MakeUseOf. (2025, April 15). *What You Can Do With GPT-4.1*. [https://www.makeuseof.com/what-you-can-do-with-gpt-4-1/](https://www.makeuseof.com/what-you-can-do-with-gpt-4-1/)
<a id="ref-76"></a>
76. OpenAI API. (n.d.). *o1*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-77"></a>
77. Bardeen AI. (n.d.). *DeepSeek R1 vs V3*. [https://www.bardeen.ai/answers/deepseek-r1-vs-v3](https://www.bardeen.ai/answers/deepseek-r1-vs-v3)
<a id="ref-78"></a>
78. Wikipedia. (2024, May 16). *GPT-4o*.(https://en.wikipedia.org/wiki/GPT-4o)
<a id="ref-79"></a>
79. OpenAI API. (n.d.). *o1-mini*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-80"></a>
80. Kili Technology. (2024, July 25). *A Guide to GPT4o Mini: OpenAI's Smaller, More Efficient Language Model*. [https://kili-technology.com/large-language-models-llms/a-guide-to-gpt4o-mini-openai-s-smaller-more-efficient-language-model](https://kili-technology.com/large-language-models-llms/a-guide-to-gpt4o-mini-openai-s-smaller-more-efficient-language-model)
<a id="ref-81"></a>
81. Mistral AI. (n.d.). *Benchmarks*. [https://docs.mistral.ai/getting-started/models/benchmark/](https://docs.mistral.ai/getting-started/models/benchmark/)
<a id="ref-82"></a>
82. OpenAI. (2025, April 16). *Introducing o3 and o4-mini*. [https://openai.com/index/introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/)
<a id="ref-83"></a>
83. Microsoft Azure. (n.d.). *Azure OpenAI Service Models overview*. [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
<a id="ref-84"></a>
84. Reddit. (n.d.). *GPT4.5 is here, but is it really an upgrade? My initial thoughts and comparisons to 4o : ChatGPTPro*.([https://www.reddit.com/r/ChatGPTPro/comments/1j55h6m/gpt45\_is\_here\_but\_is\_it\_really\_an\_upgrade\_my/](https://www.reddit.com/r/ChatGPTPro/comments/1j55h6m/gpt45_is_here_but_is_it_really_an_upgrade_my/))
<a id="ref-85"></a>
85. OpenAI. (2024, May 13). *GPT-4o System Card*. [https://openai.com/index/gpt-4o-system-card/](https://openai.com/index/gpt-4o-system-card/)
<a id="ref-86"></a>
86. OpenAI API. (n.d.). *o3-mini*. [https://platform.openai.com/docs/models](https://platform.openai.com/docs/models)
<a id="ref-87"></a>
87. Microsoft Azure. (n.d.). *Azure OpenAI Service Models overview*. [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)
<a id="ref-88"></a>
88. OpenAI. (2025, April 16). *o3 and o4-mini System Card*. [https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf)
<a id="ref-89"></a>
89. WandB. (2025, February 27). *Evaluating Claude 3.7 Sonnet Performance: reasoning and cost optimization*.(https://wandb.ai/byyoung3/Generative-AI/reports/Evaluating-Claude-3-7-Sonnet-Performance-reasoning-and-cost-optimization--VmlldzoxMTYzNDEzNQ)
<a id="ref-90"></a>
90. Reddit. (n.d.). *Claude 3.7 benchmarks : ClaudeAI*. [https://www.reddit.com/r/ClaudeAI/comments/1ix9bou/claude\_37\_benchmarks/](https://www.google.com/search?q=https://www.reddit.com/r/ClaudeAI/comments/1ix9bou/claude_37_benchmarks/)
<a id="ref-91"></a>
91. FutureSkills Academy. (2025, February 1). *OpenAI o3-mini: A Cost-Effective Reasoning Model*. [https://futureskillsacademy.com/blog/openai-o3-mini/](https://futureskillsacademy.com/blog/openai-o3-mini/)
<a id="ref-92"></a>
92. OpenAI. (2025, April 16). *Thinking with images*. [https://openai.com/index/thinking-with-images/](https://openai.com/index/thinking-with-images/)
<a id="ref-93"></a>
93. DataCamp. (2025, February 28). *Claude 3.7 Sonnet: Anthropic's Latest Model*. [https://www.datacamp.com/blog/claude-3-7-sonnet](https://www.datacamp.com/blog/claude-3-7-sonnet)
<a id="ref-94"></a>
94. DocsBot AI. (n.d.). *Compare Mistral Large 2 vs GPT-4 32K*. [https://docsbot.ai/models/compare/mistral-large-2/gpt-4-32k](https://docsbot.ai/models/compare/mistral-large-2/gpt-4-32k)
<a id="ref-95"></a>
95. Exploding Topics. (2025, March 13). *List of LLMs*. [https://explodingtopics.com/blog/list-of-llms](https://explodingtopics.com/blog/list-of-llms)
<a id="ref-96"></a>
96. Reddit. (n.d.). *Gemini 2.0 Flash vs 1.5 Pro vs 2.0 Flash-Lite for coding? : Bard*.(https://www.reddit.com/r/Bard/comments/1j6ai3s/gemini\_20\_flash\_vs\_15\_pro\_vs\_20\_flashlite\_for/)
<a id="ref-97"></a>
97. NIST. (2024, December 12). *Pre-Deployment Evaluation of OpenAI’s o1 Model*. [https://www.nist.gov/news-events/news/2024/12/pre-deployment-evaluation-openais-o1-model](https://www.nist.gov/news-events/news/2024/12/pre-deployment-evaluation-openais-o1-model)
<a id="ref-98"></a>
98. Exploding Topics. (2025, March 13). *List of LLMs*. [https://explodingtopics.com/blog/list-of-llms](https://explodingtopics.com/blog/list-of-llms)
<a id="ref-99"></a>
99. Microsoft Tech Community. (2025, April 15). *Discover the new multi-lingual high-quality Phi-3.5 SLMs*. [https://techcommunity.microsoft.com/blog/azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/4225280](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/discover-the-new-multi-lingual-high-quality-phi-3-5-slms/4225280)
<a id="ref-100"></a>
100. OpenCV. (2025, February 18). *Grok-3: A New Era of AI Performance*. [https://opencv.org/blog/grok-3/](https://opencv.org/blog/grok-3/)
<a id="ref-101"></a>
101. Reddit. (n.d.). *Rumoured GPT-4 Architecture (Simplified) : LocalLLaMA*. [https://www.reddit.com/r/LocalLLaMA/comments/1c1en6n/rumoured\_gpt4\_architecture\_simplified/](https://www.reddit.com/r/LocalLLaMA/comments/1c1en6n/rumoured_gpt4_architecture_simplified/)
<a id="ref-102"></a>
102. OpenAI. (2024, September 12). *OpenAI o1 System Card*. [https://openai.com/index/openai-o1-system-card/](https://openai.com/index/openai-o1-system-card/)
<a id="ref-103"></a>
103. Willison, S. (2025, April 14). *GPT-4.1: Three new million token input models from OpenAI, including their cheapest model yet*. [https://simonwillison.net/2025/Apr/14/gpt-4-1/](https://simonwillison.net/2025/Apr/14/gpt-4-1/)
<a id="ref-104"></a>
104. MyScale. (2024, April 15). *Llama 3.1 405B, 70B, 8B: A Quick Comparison*. [https://myscale.com/blog/llama-3-1-405b-70b-8b-quick-comparison/](https://myscale.com/blog/llama-3-1-405b-70b-8b-quick-comparison/)
<a id="ref-105"></a>
105. Techxmedia. (2025, April 15). *OpenAI Introduces GPT-4.1 With Major Performance Upgrades*. [https://techxmedia.com/en/openai-introduces-gpt-4-1-with-major-performance-upgrades/](https://techxmedia.com/en/openai-introduces-gpt-4-1-with-major-performance-upgrades/)
<a id="ref-106"></a>
106. DocsBot AI. (n.d.). *Compare Mistral Large vs Mistral Large 2*. [https://docsbot.ai/models/compare/mistral-large/mistral-large-2](https://docsbot.ai/models/compare/mistral-large/mistral-large-2)
<a id="ref-107"></a>
107. Microsoft Azure. (2024, May 14). *OpenAI’s fastest model, GPT-4o mini, is now available on Azure AI*. [https://azure.microsoft.com/en-us/blog/openais-fastest-model-gpt-4o-mini-is-now-available-on-azure-ai/](https://www.google.com/search?q=https://azure.microsoft.com/en-us/azure/ai-services/openai/whats-new)
<a id="ref-108"></a>
108. Microsoft Research. (2024, August 30). *Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone*. [https://arxiv.org/pdf/2404.14219](https://www.google.com/search?q=https://arxiv.org/pdf/2404.14219)
<a id="ref-109"></a>
109. OpenAI. (2024, July 18). *GPT-4o mini: Advancing cost-efficient intelligence*. [https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)
<a id="ref-110"></a>
110. Helicone. (2025, February 18). *Grok 3 Benchmark Comparison: How Does It Stack Up?*. [https://www.helicone.ai/blog/grok-3-benchmark-comparison](https://www.helicone.ai/blog/grok-3-benchmark-comparison)
<a id="ref-111"></a>
111. DocsBot AI. (n.d.). *OpenAI's GPT-4.5: Most Powerful AI Model Yet*. [https://docsbot.ai/article/openais-gpt-4-5-most-powerful-ai-model-yet](https://docsbot.ai/article/openais-gpt-4-5-most-powerful-ai-model-yet)
<a id="ref-112"></a>
112. Microsoft Research. (2024, August 30). *Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone*. [https://arxiv.org/html/2404.14219v3](https://arxiv.org/html/2404.14219v3)
<a id="ref-113"></a>
113. Wikipedia. (2025, April 18). *OpenAI o3*. [https://en.wikipedia.org/wiki/OpenAI\_o3](https://en.wikipedia.org/wiki/OpenAI_o3)
<a id="ref-114"></a>
114. TechTarget. (n.d.). *GPT-4o explained: Everything you need to know*.([https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know\#:\~:text=The%20multimodal%20capabilities%20of%20GPT,Data%20analysis](https://www.google.com/search?q=https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know%23:~:text%3DThe%2520multimodal%2520capabilities%2520of%2520GPT,Data%2520analysis).)
<a id="ref-115"></a>
115. Google Developers Blog. (2025, April 9). *Start building with the Gemini 2.0 Flash family*. [https://developers.googleblog.com/en/start-building-with-the-gemini-2-0-flash-family/](https://developers.googleblog.com/en/start-building-with-the-gemini-2-0-flash-family/)
<a id="ref-116"></a>
116. Reddit. (n.d.). *GPT4o Features Summary : singularity*. [https://www.reddit.com/r/singularity/comments/1cr7tvm/gpt4o\_features\_summary/](https://www.reddit.com/r/singularity/comments/1cr7tvm/gpt4o_features_summary/)
<a id="ref-117"></a>
117. OpenAI Help Center. (n.d.). *How can I access GPT-4, GPT-4o, and GPT-4o mini?*. [https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4o-and-gpt-4o-mini](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4o-and-gpt-4o-mini)
<a id="ref-118"></a>
118. Anthropic. (2025, February 24). *Claude 3.7 Sonnet*. [https://www.anthropic.com/news/claude-3-7-sonnet](https://www.anthropic.com/news/claude-3-7-sonnet)
<a id="ref-119"></a>
119. OpenAI. (2024, September 12). *Introducing OpenAI o1-mini: Advancing cost-efficient reasoning*. [https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/](https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning/)
<a id="ref-120"></a>
120. Unthread. (2024, May 14). *The 5 Coolest Features of GPT4o*. [https://unthread.io/blog/the-5-coolest-features-of-gpt4o/](https://unthread.io/blog/the-5-coolest-features-of-gpt4o/)
<a id="ref-121"></a>
121. ManageEngine. (2024, September 20). *OpenAI's o1: One small step for man, one giant leap for mankind?*. [https://insights.manageengine.com/artificial-intelligence/openai-o1/](https://insights.manageengine.com/artificial-intelligence/openai-o1/)
<a id="ref-122"></a>
122. Google Developers Blog. (2025, April 16). *Gemini 2.0 Family expands for developers*. [https://developers.googleblog.com/en/gemini-2-family-expands/](https://developers.googleblog.com/en/gemini-2-family-expands/)
<a id="ref-123"></a>
123. OpenAI. (2025, April 16). *o3 and o4-mini System Card*. [https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf](https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf)
<a id="ref-124"></a>
124. PYMNTS. (2025, April 18). *OpenAI Says Its Latest Models Bring More Capable AI Agents to Business*. [https://www.pymnts.com/artificial-intelligence-2/2025/openai-says-its-latest-models-bring-more-capable-ai-agents-to-business/](https://www.pymnts.com/artificial-intelligence-2/2025/openai-says-its-latest-models-bring-more-capable-ai-agents-to-business/)
<a id="ref-125"></a>
125. Acorn. (n.d.). *OpenAI*. [https://www.acorn.io/resources/learning-center/openai/](https://www.acorn.io/resources/learning-center/openai/)
<a id="ref-126"></a>
126. OpenAI. (2024, May 13). *Introducing GPT-4o and more tools to ChatGPT free users*. [https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/](https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/)
<a id="ref-127"></a>
127. Tomsguide. (2025, April 12). *OpenAI is retiring GPT-4 from ChatGPT—here's what that means for you*. [https://www.tomsguide.com/ai/chatgpt/openai-is-retiring-gpt-4-from-chatgpt-heres-what-that-means-for-you](https://www.tomsguide.com/ai/chatgpt/openai-is-retiring-gpt-4-from-chatgpt-heres-what-that-means-for-you)
<a id="ref-128"></a>
128. OpenAI Developer Community. (2024, May 29). *OpenAI has begun training its next frontier model*. [https://community.openai.com/t/openai-has-begun-training-its-next-frontier-model/784085](https://community.openai.com/t/openai-has-begun-training-its-next-frontier-model/784085)
<a id="ref-129"></a>
129. Vellum AI. (2024, September 21). *Analysis: OpenAI o1 vs GPT-4o*. [https://www.vellum.ai/blog/analysis-openai-o1-vs-gpt-4o](https://www.vellum.ai/blog/analysis-openai-o1-vs-gpt-4o)
<a id="ref-130"></a>
130. IBM. (2024, May 15). *What is GPT-4o? Understanding OpenAI’s Newest Model*. [https://www.ibm.com/think/topics/gpt-4o](https://www.ibm.com/think/topics/gpt-4o)
<a id="ref-131"></a>
131. Vellum AI. (2024, April 15). *Llama 3.3 70b vs GPT-4o*. [https://www.vellum.ai/blog/llama-3-3-70b-vs-gpt-4o](https://www.vellum.ai/blog/llama-3-3-70b-vs-gpt-4o)
<a id="ref-132"></a>
132. MeetCody AI. (2024, September 13). *OpenAI o1 Pricing & Performance Comparison*. [https://meetcody.ai/blog/openai-o1-pricing-performance-comparison/](https://meetcody.ai/blog/openai-o1-pricing-performance-comparison/)
<a id="ref-133"></a>
133. Section School. (2024, May 14). *What is GPT4o?*. [https://www.sectionschool.com/blog/what-is-gpt4o](https://www.sectionschool.com/blog/what-is-gpt4o)
<a id="ref-134"></a>
134. Botpress. (2025, April 15). *Everything you should know about GPT-5*. [https://botpress.com/blog/everything-you-should-know-about-gpt-5](https://botpress.com/blog/everything-you-should-know-about-gpt-5)
<a id="ref-135"></a>
135. DataCamp. (2024, May 14). *What is GPT-4o?*. [https://www.datacamp.com/blog/what-is-gpt-4o](https://www.datacamp.com/blog/what-is-gpt-4o)
<a id="ref-136"></a>
136. Reddit. (n.d.). *Ok o3 and o4 mini are here and they really has tool use : ChatGPT*.([https://www.reddit.com/r/ChatGPT/comments/1k0pway/ok\_o3\_and\_o4\_mini\_are\_here\_and\_they\_really\_has/](https://www.google.com/search?q=https://www.reddit.com/r/ChatGPT/comments/1k0pway/ok_o3_and_o4_mini_are_here_and_they_really_has/))
<a id="ref-137"></a>
137. Reddit. (n.d.). *GPT4.5 Benchmark Performance : singularity*. [https://www.reddit.com/r/singularity/comments/1izp75f/gpt45\_benchmark\_performance/](https://www.reddit.com/r/singularity/comments/1izp75f/gpt45_benchmark_performance/)
<a id="ref-138"></a>
138. Arize AI. (2024, September 13). *Exploring OpenAI o1-preview and o1-mini*. [https://arize.com/blog/exploring-openai-o1-preview-and-o1-mini/](https://arize.com/blog/exploring-openai-o1-preview-and-o1-mini/)
